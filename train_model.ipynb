{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2d860fac",
   "metadata": {},
   "source": [
    "## 1. Environment Setup and Data Acquisition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a941e5c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install MONAI and medical imaging dependencies\n",
    "!pip install -q \"monai[low_resource, nibabel, tqdm, ignite]\" \n",
    "!pip install -q matplotlib\n",
    "\n",
    "import os\n",
    "import glob\n",
    "import torch\n",
    "import numpy as np\n",
    "import nibabel as nib\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm.notebook import tqdm\n",
    "from monai.utils import set_determinism\n",
    "from monai.transforms import (\n",
    "    Compose, LoadImaged, EnsureChannelFirstd, ScaleIntensityd, \n",
    "    Resized, ToTensord, Lambdad, ConcatItemsd\n",
    ")\n",
    "from monai.networks.nets import UNet\n",
    "from monai.losses import DiceLoss\n",
    "from monai.metrics import DiceMetric, ConfusionMatrixMetric\n",
    "from monai.data import Dataset, DataLoader, decollate_batch\n",
    "\n",
    "set_determinism(seed=42)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Extract dataset\n",
    "!mkdir -p /kaggle/working/brats_data\n",
    "!tar -xf /kaggle/input/brats-2021-task1/BraTS2021_Training_Data.tar -C /kaggle/working/brats_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bc06fd0",
   "metadata": {},
   "source": [
    "## 2. Multi-Modal Data Mapping and Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1190aa38",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = \"/kaggle/working/brats_data\"\n",
    "\n",
    "flair_list = sorted(glob.glob(os.path.join(data_dir, \"**/*_flair.nii.gz\"), recursive=True))\n",
    "t1_list = sorted(glob.glob(os.path.join(data_dir, \"**/*_t1.nii.gz\"), recursive=True))\n",
    "t2_list = sorted(glob.glob(os.path.join(data_dir, \"**/*_t2.nii.gz\"), recursive=True))\n",
    "label_list = sorted(glob.glob(os.path.join(data_dir, \"**/*_seg.nii.gz\"), recursive=True))\n",
    "\n",
    "data_dicts = [\n",
    "    {\"flair\": f, \"t1\": t1, \"t2\": t2, \"label\": l} \n",
    "    for f, t1, t2, l in zip(flair_list, t1_list, t2_list, label_list)\n",
    "]\n",
    "\n",
    "train_transforms = Compose([\n",
    "    LoadImaged(keys=[\"flair\", \"t1\", \"t2\", \"label\"]),\n",
    "    EnsureChannelFirstd(keys=[\"flair\", \"t1\", \"t2\", \"label\"]),\n",
    "    ScaleIntensityd(keys=[\"flair\", \"t1\", \"t2\"]), \n",
    "    ConcatItemsd(keys=[\"flair\", \"t1\", \"t2\"], name=\"image\"),\n",
    "    Lambdad(keys=\"label\", func=lambda x: torch.where(x > 0, 1, 0)),\n",
    "    Resized(keys=[\"image\", \"label\"], spatial_size=(128, 128, 64)),\n",
    "    ToTensord(keys=[\"image\", \"label\"]),\n",
    "])\n",
    "\n",
    "train_ds = Dataset(data=data_dicts[:300], transform=train_transforms)\n",
    "train_loader = DataLoader(train_ds, batch_size=2, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3dba66d2",
   "metadata": {},
   "source": [
    "## 3. Model Training and Optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aec1a8de",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = UNet(\n",
    "    spatial_dims=3,\n",
    "    in_channels=3,\n",
    "    out_channels=2,\n",
    "    channels=(16, 32, 64, 128, 256),\n",
    "    strides=(2, 2, 2, 2),\n",
    "    num_res_units=2,\n",
    ").to(device)\n",
    "\n",
    "loss_function = DiceLoss(to_onehot_y=True, softmax=True)\n",
    "optimizer = torch.optim.Adam(model.parameters(), 1e-4)\n",
    "max_epochs = 50\n",
    "\n",
    "for epoch in range(max_epochs):\n",
    "    model.train()\n",
    "    epoch_loss = 0\n",
    "    progress_bar = tqdm(train_loader, desc=f\"Epoch {epoch+1}/{max_epochs}\")\n",
    "    \n",
    "    for batch_data in progress_bar:\n",
    "        inputs, labels = batch_data[\"image\"].to(device), batch_data[\"label\"].to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        loss = loss_function(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        epoch_loss += loss.item()\n",
    "\n",
    "    if (epoch + 1) % 10 == 0:\n",
    "        torch.save(model.state_dict(), f\"unet_brats_multimodal_epoch_{epoch+1}.pth\")\n",
    "\n",
    "torch.save(model.state_dict(), \"suvarna_tumor_detector_v1.pth\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a12930d3",
   "metadata": {},
   "source": [
    "## 4. Evaluation and Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a7e54e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_clinical_report(patient_idx=305):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        single_ds = Dataset(data=data_dicts[patient_idx:patient_idx+1], transform=train_transforms)\n",
    "        batch = next(iter(DataLoader(single_ds, batch_size=1)))\n",
    "        inputs, labels = batch[\"image\"].to(device), batch[\"label\"].to(device)\n",
    "        \n",
    "        output = model(inputs)\n",
    "        prediction = torch.argmax(output, dim=1).cpu().numpy()[0]\n",
    "        slice_idx = 32\n",
    "        input_data = inputs[0].cpu().numpy()\n",
    "        \n",
    "        plt.figure(figsize=(15, 8))\n",
    "        plt.subplot(1, 4, 1); plt.title(\"FLAIR\"); plt.imshow(input_data[0, :, :, slice_idx], cmap=\"gray\")\n",
    "        plt.subplot(1, 4, 2); plt.title(\"T2\"); plt.imshow(input_data[2, :, :, slice_idx], cmap=\"gray\")\n",
    "        plt.subplot(1, 4, 3); plt.title(\"Ground Truth\"); plt.imshow(labels[0, 0, :, :, slice_idx].cpu(), cmap=\"Reds\")\n",
    "        plt.subplot(1, 4, 4); plt.title(\"AI Prediction\"); plt.imshow(prediction[:, :, slice_idx], cmap=\"Greens\")\n",
    "        plt.show()\n",
    "\n",
    "# Run Evaluation Metrics\n",
    "dice_metric = DiceMetric(include_background=False, reduction=\"mean\")\n",
    "model.eval()\n",
    "for test_data in DataLoader(Dataset(data=data_dicts[300:350], transform=train_transforms), batch_size=1):\n",
    "    with torch.no_grad():\n",
    "        outputs = model(test_data[\"image\"].to(device))\n",
    "        preds = torch.argmax(outputs, dim=1, keepdim=True)\n",
    "        dice_metric(y_pred=preds, y=test_data[\"label\"].to(device))\n",
    "\n",
    "print(f\"Final Dice Score: {dice_metric.aggregate().item():.4f}\")\n",
    "# Sample visualization\n",
    "generate_clinical_report(patient_idx=440)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
